  ğŸ§© Databricks Declarative Pipelines (Delta Live Tables)

This project demonstrates the implementation of Databricks Declarative Pipelines, also known as Delta Live Tables (DLT) â€” a modern framework for building reliable, scalable, and automated data pipelines on the Databricks Lakehouse Platform.
The goal of this project is to design and orchestrate a streaming data pipeline that seamlessly transforms raw data into clean, enriched, and analytics-ready datasets following the Medallion Architecture (Bronze â†’ Silver â†’ Gold).

ğŸ“ Folder Structure
DeclarativePipelines/
â”‚
â”œâ”€â”€ transformations_SourceCode/
â”‚   â”œâ”€â”€ bronze/      # Raw ingestion layer
â”‚   â”œâ”€â”€ silver/      # Cleansed and enriched data
â”‚   â””â”€â”€ gold/        # Aggregated business-level tables
â”‚
â”œâ”€â”€ notebooks/       # DLT notebooks defining views and tables
â””â”€â”€ configs/         # DLT pipeline configurations

ğŸ§  Key Concepts
ğŸ§± Streaming Tables and Materialized Views
âš™ï¸ Auto CDC (Change Data Capture) and Slowly Changing Dimensions (SCD Type 1 & 2)
ğŸ“Š Data Quality Checks & Expectations
ğŸ”„ Append Flows and Incremental Processing
ğŸš€ End-to-End ETL Pipeline with DLT Orchestration

ğŸ—ï¸ Tech Stack
Databricks | Delta Live Tables | PySpark
Structured Streaming | Auto Loader
Delta Lake | SQL | Medallion Architecture

ğŸ“ˆ Outputs
![image alt](https://github.com/Charvi-M-J/Declarative-Pipelines/blob/1f60d2f5534e5ebc5a0d991f864cac1097466e1b/Screenshot%202025-11-04%20202233.png)
![image alt](https://github.com/Charvi-M-J/Declarative-Pipelines/blob/39dd5aa42cc0ab46aed20416474516517e7a131b/Screenshot%202025-11-03%20194941.png)
![image_alt](https://github.com/Charvi-M-J/Declarative-Pipelines/blob/39dd5aa42cc0ab46aed20416474516517e7a131b/Screenshot%202025-11-03%20191432.png)
